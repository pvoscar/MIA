{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "\n",
    "# <center> <font color= #000047> Módulo 2: Aprendizaje supervizado: Regresión Lineal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Aprendizaje Supervizado se podría definir como un tipo de aprendizaje en IA en el que un algoritmo es entrenado con variables que incluyen los valores que queremos predecir; a estos valores conocidos se les llama `“etiquetas”` y se usan también para la evaluación del modelo. El aprendizaje supervisado se puede subdividir en dos tipos: \n",
    "\n",
    "- Clasificación\n",
    "\n",
    "- Regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación\n",
    "\n",
    "En cuanto a clasificación, el objetivo es predecir las etiquetas de clase categóricas de nuevos registros, con base en observaciones pasadas. Dependiendo de la etiqueta, se puede decir que la clasificación es binaria o multiclase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión\n",
    "\n",
    "Respecto a regresión, se trata del proceso estadístico predictivo en el que el modelo intenta predecir un valor continuo (como ventas, precio, calificaciones) mediante la relación entre variables dependientes e independientes. Es decir, se encuentra una ecuación en la que se sustituyen los valores de las variables y como resultado se obtiene el valor a predecir "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunos algortimos de Aprendizaje Supervizado\n",
    "\n",
    "- **Regresión lineal:** Se trata de una regresión en la que al graficar la ecuación se forma una línea recta. Para obtener dicha ecuación, se usa el método de los cuadrados mínimos.\n",
    "\n",
    "\n",
    "- **Regresión logística:** Es una regresión usada principalmente en problemas de clasificación binaria. A pesar de la aparente incongruencia, se trata de una regresión porque el resultado de la ecuación es la probabilidad de que pertenezca a una clase, que dependiendo del umbral que se utilice, se clasifica como positivo o negativo.\n",
    "\n",
    "\n",
    "- **Support Vector Machine (SVM):** Típicamente se usa para problemas de clasificación, pero también se puede usar para regresión. En este algoritmo se construye un hiperplano que separa las clases de datos lo más posible.\n",
    "\n",
    "\n",
    "- **Árboles de decisión:** Algoritmo de clasificación similar a un diagrama de flujo, en el que se evalúan valores en cada nodo para llegar a una clasificación al final.\n",
    "\n",
    "\n",
    "- **Random Forest:** Este algoritmo consiste en combinar una gran cantidad de árboles de decisión independientes entre sí para reducir la varianza. Debido al conjunto de árboles, se le dio el nombre de “bosque”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal (Repaso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consideremos un polinomio de grado uno:\n",
    "\n",
    "$$y = \\beta_1 x + \\beta_0.$$\n",
    "\n",
    "Esta es una **línea recta** que tiene pendiente $\\beta_1$. Sabemos que habrá una línea conectando dos puntos cualesquiera. Por tanto, *una ecuación polinómica de primer grado es un ajuste perfecto entre dos puntos*.\n",
    "\n",
    "Si consideramos ahora un polinomio de segundo grado,\n",
    "\n",
    "$$y = \\beta_2 x^2 + \\beta_1 x + \\beta_0,$$\n",
    "\n",
    "este se ajustará exactamente a tres puntos. Si aumentamos el grado de la función a la de un polinomio de tercer grado, obtenemos:\n",
    "\n",
    "$$y = \\beta_3 x^3 + \\beta_2 x^2 + \\beta_1 x + \\beta_0,$$\n",
    "\n",
    "que se ajustará a cuatro puntos.\n",
    "\n",
    "**Ejemplos**\n",
    "1. Encontrar la línea recta que pasa exactamente por los puntos $(0,1)$ y $(1,0)$.\n",
    "2. Encontrar la parábola que pasa exactamente por los puntos $(-1,1)$, $(0,0)$ y $(1,1)$.\n",
    "\n",
    "**Solución**\n",
    "1. Consideramos $y=\\beta_1 x + \\beta_0$. Evaluando en el punto $(0,1)$, obtenemos $\\beta_1(0) + \\beta_0 = 1$. Ahora, evaluando en el punto $(1,0)$, obtenemos $\\beta_1(1) + \\beta_0 = 0$. De esta manera,\n",
    "$$\\left[\\begin{array}{cc} 1 & 0 \\\\ 1 & 1\\end{array}\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1\\end{array}\\right]=\\left[\\begin{array}{c} 1 \\\\ 0\\end{array}\\right].$$\n",
    "Resolviendo, $\\beta_0=-\\beta_1=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar numpy y el matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Consideramos $y=\\beta_2 x^2 + \\beta_1 x + \\beta_0$. Evaluando en el punto $(-1,1)$, obtenemos $\\beta_2(-1)^2 + \\beta_1(-1) + \\beta_0 = 1$. Ahora, evaluando en el punto $(0,0)$, obtenemos $\\beta_2(0)^2 + \\beta_1(0) + \\beta_0 = 0$. Finalmente, evaluando en el punto $(1,1)$, obtenemos $\\beta_2(1)^2 + \\beta_1(1) + \\beta_0 = 1$. De esta manera,\n",
    "$$\\left[\\begin{array}{ccc} 1 & -1 & 1 \\\\ 1 & 0 & 0 \\\\ 1 & 1 & 1 \\end{array}\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\end{array}\\right]=\\left[\\begin{array}{c} 1 \\\\ 0 \\\\ 1 \\end{array}\\right].$$\n",
    "Resolviendo, $\\beta_0=\\beta_1=0$ y $\\beta_2=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué tienen en común los anteriores problemas?\n",
    "Las curvas están completamente determinadas por los puntos (datos limpios, suficientes y necesarios).\n",
    "\n",
    "Esto se traduce en que, al llevar el problema a un sistema de ecuaciones lineales, existe una única solución: **no hay necesidad, ni se puede optimizar nada**.\n",
    "\n",
    "¿Tendremos datos así de '*bonitos*' en la vida real?\n",
    "\n",
    "La realidad es que los datos que encontraremos en nuestra vida profesional se parecen más a esto..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo ajustamos una curva a esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos entonces ajustes de la forma $\\hat{f}(x) = \\beta_0+\\beta_1 x = \\left[1 \\quad x\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\end{array}\\right]=\\left[1 \\quad x\\right]\\boldsymbol{\\beta}$ (lineas rectas).\n",
    "\n",
    "Para decir '*mejor*', tenemos que definir algún sentido en que una recta se ajuste *mejor* que otra.\n",
    "\n",
    "**Mínimos cuadrados**: el objetivo es seleccionar los coeficientes $\\boldsymbol{\\beta}=\\left[\\beta_0 \\quad \\beta_1 \\right]^T$, de forma que la función evaluada en los puntos $x_i$ ($\\hat{f}(x_i)$) aproxime los valores correspondientes $y_i$.\n",
    "\n",
    "La formulación por mínimos cuadrados, encuentra los $\\boldsymbol{\\beta}=\\left[\\beta_0 \\quad \\beta_1 \\right]^T$ que minimiza\n",
    "$$\\frac{1}{2n}\\sum_{i=1}^{n}(y_i-\\hat{f}(x_i))^2=\\frac{1}{2n}\\sum_{i=1}^{n}(y_i-(\\beta_0+ \\beta_1x_i))^2=\\frac{1}{2n}\\sum_{i=1}^{n}(y_i-\\left[1 \\quad x_i\\right]\\boldsymbol{\\beta})^2=\\frac{1}{2n}\\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2,$$\n",
    "\n",
    "donde $\\boldsymbol{y}=\\left[y_1\\quad\\dots\\quad y_n\\right]^T$, y $\\boldsymbol{X}=\\left[\\begin{array}{ccc}1 & x_1\\\\ \\vdots & \\vdots \\\\ 1 & x_n\\end{array}\\right].$ Esto es,\n",
    "\n",
    "$$\\boldsymbol{\\beta}^{ls} = \\arg \\min_{\\boldsymbol{\\beta}} \\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo (gradiente descendente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El objetivo es estimar el modelo $\\hat{y} = \\hat{f}(x) = \\beta_0+\\beta_1 x = \\left[1 \\quad x\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\end{array}\\right]=\\left[1 \\quad x\\right]\\boldsymbol{\\beta}$ (lineas rectas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ex1data1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementar la función de costo \n",
    "\n",
    "Formalmente definimos la funcion de costo como el error cuadrático medio, qué deberemos minimizar.\n",
    "\n",
    "$$ J(\\beta) = \\frac{1}{2m}\\sum_{i=1}^m (\\hat{y}(x_i) - y_i)^2$$\n",
    "\n",
    "$\\beta = [\\beta_0, \\beta_1]$\n",
    "\n",
    "si derivamos parcialmente e igualamos a cero $\\frac{\\partial J(\\beta)}{\\partial \\beta}=0$\n",
    "\n",
    "tendríamos que las ecuaciones del algoritmo de gradiente descendente son:\n",
    "\n",
    "$$ \\beta_0 = \\beta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i)$$\n",
    "\n",
    "$$ \\beta_1 = \\beta_1 - \\alpha \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i)x_i$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficar un función de costo cualquiera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$X=[1;x]$$\n",
    "$$\\beta=[\\beta_0;\\beta_1]$$\n",
    "$$\\hat{y}=X^T\\beta = \\beta_1 x +\\beta_0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementacion de la función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\beta_0 = \\beta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i)$$\n",
    "\n",
    "$$ \\beta_1 = \\beta_1 - \\alpha \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i)x_i$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = 1.166 x - 3.63$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir un nuevo valor\n",
    "\n",
    "# y_pred = [x,1]*beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo (scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el módulo optimize de la librería scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros importantes:\n",
    "- fun: función $f(x)$, se debe definir antes de llamar minimize, como `def f(x): ... return ...`\n",
    "- x0: valor inicial. En una función no lineal, en general, hay múltiples mínimos. Dependiendo de la semilla caerá en uno de esos mínimos. Se ingresa como $x0 = \\text{np.array}([x_{01},\\dots,x_{0n}])$.\n",
    "- bounds: como en linprog.\n",
    "- constraints: funciones que definen las restricciones $g_i(x)$ y $h_j(x)$. Se definen igual que $f(x)$ y se ingresan como {'ineq': g_i, 'eq': h_j}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero debemos construir la función objetivo y la semilla inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica de los puntos y la recta ajustada\n",
    "# Graficar la recta resultamte que más se ajusta a lso datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Usando la librería de sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **model.coef**: Coeficientes que acompañan a la variable independiente $\\beta_1, ..., \\beta_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **model.intercept_**: Coeficiente de intercepción al eje de las abcisas $\\beta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo obtenido:\n",
    "$$ \\hat{y} = 1.19x -3.895$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la recta resultamte que más se ajusta a lso datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cómo predecir un nuevo elemento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Polinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicar un modelo polinomial de grado 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat = beta_2*x^2 + beta_1*x + beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad : Predecir los niveles utilizando un modelo polinomial de grado 3\n",
    "\n",
    "- Crear un modelo polinomial de grado 3\n",
    "- Predecir los siguientes niveles: x_new=[11, 13, 15]\n",
    "- Graficar los salarios de los valores de x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = \\beta_3 x^3 + \\beta_2 x^2 + \\beta_1 x + \\beta_0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal Multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
